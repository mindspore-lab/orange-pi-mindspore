{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åŸºäº OrangePi çš„å¤šæ¨¡æ€ä¿„è¯­ VQA å¾®è°ƒå…¨æµç¨‹\n",
    "\n",
    "æœ¬ Notebook æ•´åˆäº†ä»æ•°æ®å‡†å¤‡åˆ°æ¨¡å‹å¯¼å‡ºçš„å®Œæ•´å¾®è°ƒæµç¨‹ã€‚åŸºäº OpenDataLab â€œä¸‡å·Â·ä¸è·¯â€ ä¿„è¯­æ•°æ®ï¼Œä½¿ç”¨ LLaMA-Factory å¯¹ Qwen2-VL æ¨¡å‹è¿›è¡Œ LoRA å¾®è°ƒã€‚\n",
    "\n",
    "> **æ³¨æ„**ï¼šæœ¬æµç¨‹ä¸åŒ…å«æ¨ç†æµ‹è¯•éƒ¨åˆ†ï¼Œä¸“æ³¨äºæ¨¡å‹çš„è®­ç»ƒä¸å¯¼å‡ºã€‚\n",
    "\n",
    "## ğŸ“‹ æµç¨‹ç›®å½•\n",
    "1. **ç¯å¢ƒå‡†å¤‡**ï¼šä¾èµ–å®‰è£…ä¸è·¯å¾„é…ç½®\n",
    "2. **æ•°æ®å¤„ç†**ï¼š\n",
    "   - å›¾ç‰‡ä¸‹è½½ä¸ç´¢å¼•æ„å»º\n",
    "   - æŸåå›¾ç‰‡æ¸…æ´—\n",
    "   - ShareGPT æ ¼å¼è½¬æ¢\n",
    "   - è®­ç»ƒ/éªŒè¯é›†åˆ†å‰²\n",
    "3. **æ•°æ®é›†æ³¨å†Œ**ï¼šé…ç½® LLaMA-Factory\n",
    "4. **æ¨¡å‹å¾®è°ƒ**ï¼šå¯åŠ¨ LoRA è®­ç»ƒ\n",
    "5. **æ¨¡å‹å¯¼å‡º**ï¼šåˆå¹¶æƒé‡å¹¶å¯¼å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡ä¸é…ç½®\n",
    "\n",
    "é¦–å…ˆå®šä¹‰å·¥ç¨‹ç›®å½•ç»“æ„ï¼Œå¹¶å®‰è£…å¿…è¦çš„ä¾èµ–åº“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'LLaMA-Factory'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///E:/Desktop/ai%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E8%B7%AF%E7%BA%BF%E7%AD%89/%E4%B8%AD%E7%A7%91%E9%99%A2%E8%BD%AF%E4%BB%B6%E5%AE%9E%E4%B9%A0%E9%A1%B9%E7%9B%AE/%E9%A1%B9%E7%9B%AE%E5%B7%A5%E7%A8%8B%E6%96%87%E4%BB%B6%E6%B5%8B%E8%AF%95/RussianVQA/LLaMA-Factory\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.57.0,<=4.57.1,>=4.49.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (4.56.1)\n",
      "Requirement already satisfied: datasets<=4.0.0,>=2.16.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (3.2.0)\n",
      "Requirement already satisfied: accelerate<=1.11.0,>=1.3.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (1.11.0)\n",
      "Requirement already satisfied: peft<=0.17.1,>=0.14.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.14.0)\n",
      "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.9.6)\n",
      "Requirement already satisfied: gradio<=5.45.0,>=4.38.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (4.44.0)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (3.9.2)\n",
      "Requirement already satisfied: tyro<0.9.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.8.14)\n",
      "Requirement already satisfied: einops in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.8.0)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (1.14.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.2.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.8.0)\n",
      "Requirement already satisfied: modelscope>=1.14.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (1.21.0)\n",
      "Requirement already satisfied: hf-transfer in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.1.9)\n",
      "Requirement already satisfied: safetensors<=0.5.3 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.4.5)\n",
      "Requirement already satisfied: fire in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.7.1)\n",
      "Requirement already satisfied: omegaconf in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (2.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (24.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (4.25.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (6.0.1)\n",
      "Requirement already satisfied: pydantic<=2.10.6 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (2.9.2)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.32.1)\n",
      "Requirement already satisfied: fastapi in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.115.6)\n",
      "Requirement already satisfied: sse-starlette in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (2.1.3)\n",
      "Requirement already satisfied: av in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (14.0.1)\n",
      "Requirement already satisfied: librosa in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.11.0)\n",
      "Requirement already satisfied: propcache!=0.4.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.2.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (3.9.1)\n",
      "Requirement already satisfied: jieba in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (0.42.1)\n",
      "Requirement already satisfied: rouge-chinese in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from llamafactory==0.9.4.dev0) (1.0.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (2.4.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (0.34.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.11.3)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (23.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.2.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.28.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (6.4.5)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.1.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.10.12)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (10.4.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.0.19)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.8.2)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.5.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from gradio-client==1.3.0->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (12.0)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from fastapi->llamafactory==0.9.4.dev0) (0.41.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from pydantic<=2.10.6->llamafactory==0.9.4.dev0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from pydantic<=2.10.6->llamafactory==0.9.4.dev0) (2.23.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from transformers!=4.52.0,!=4.57.0,<=4.57.1,>=4.49.0->llamafactory==0.9.4.dev0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from transformers!=4.52.0,!=4.57.0,<=4.57.1,>=4.49.0->llamafactory==0.9.4.dev0) (0.22.0)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (13.4.2)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (1.8.0)\n",
      "Requirement already satisfied: colorama>=0.4.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (0.4.6)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from uvicorn->llamafactory==0.9.4.dev0) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from uvicorn->llamafactory==0.9.4.dev0) (0.14.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from fire->llamafactory==0.9.4.dev0) (3.1.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from librosa->llamafactory==0.9.4.dev0) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from librosa->llamafactory==0.9.4.dev0) (0.60.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from librosa->llamafactory==0.9.4.dev0) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from librosa->llamafactory==0.9.4.dev0) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from librosa->llamafactory==0.9.4.dev0) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from librosa->llamafactory==0.9.4.dev0) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from librosa->llamafactory==0.9.4.dev0) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from librosa->llamafactory==0.9.4.dev0) (1.0.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from librosa->llamafactory==0.9.4.dev0) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from librosa->llamafactory==0.9.4.dev0) (1.1.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from omegaconf->llamafactory==0.9.4.dev0) (4.9.3)\n",
      "Requirement already satisfied: six in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from rouge-chinese->llamafactory==0.9.4.dev0) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from anyio<5.0,>=3.0->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from anyio<5.0,>=3.0->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from anyio<5.0,>=3.0->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from aiohttp->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (4.0.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from httpx>=0.24.1->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from httpx>=0.24.1->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.0.7)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from numba>=0.51.0->librosa->llamafactory==0.9.4.dev0) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from pooch>=1.1->librosa->llamafactory==0.9.4.dev0) (3.10.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from requests>=2.32.2->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0) (2.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from scikit-learn>=1.1.0->librosa->llamafactory==0.9.4.dev0) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (1.17.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (3.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from typer<1.0,>=0.12->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.5.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (2.21)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from sympy->torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.3.0)\n",
      "Building wheels for collected packages: llamafactory\n",
      "  Building editable for llamafactory (pyproject.toml): started\n",
      "  Building editable for llamafactory (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for llamafactory: filename=llamafactory-0.9.4.dev0-0.editable-py3-none-any.whl size=29152 sha256=20a51edff487fbced4976d6ef553dc8dd63ddbcaae69953fa2514c5378689407\n",
      "  Stored in directory: C:\\Users\\14468\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-13e6id3f\\wheels\\87\\9b\\25\\2b87b069dd194bc914f15dc058f969761813226192711104da\n",
      "Successfully built llamafactory\n",
      "Installing collected packages: llamafactory\n",
      "  Attempting uninstall: llamafactory\n",
      "    Found existing installation: llamafactory 0.9.4.dev0\n",
      "    Uninstalling llamafactory-0.9.4.dev0:\n",
      "      Successfully uninstalled llamafactory-0.9.4.dev0\n",
      "Successfully installed llamafactory-0.9.4.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modelscope in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (1.21.0)\n",
      "Requirement already satisfied: requests in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from modelscope) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\14468\\.conda\\envs\\pytorch\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# === å®‰è£…ä¾èµ– ===\n",
    "!git clone https://github.com/hiyouga/LLaMA-Factory.git\n",
    "!pip install -e LLaMA-Factory/[metrics]\n",
    "!pip install modelscope requests tqdm pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb480f",
   "metadata": {},
   "source": [
    "### éœ€ä¸‹è½½â€ä¹¦ç”Ÿä¸‡å·ä¿„è¯­å›¾æ–‡æ ‡æ³¨æ•°æ®é›†å¹¶ä¸”æ”¾åˆ°å·¥ä½œç›®å½•ä¸­\n",
    "https://opendatalab.com/OpenDataLab/WanJuanSiLu2O/blob/main/raw/image/ru/ru_image_caption.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·¥ä½œç›®å½•å·²å°±ç»ª: e:\\Desktop\\aiç›¸å…³èµ„æ–™\\å­¦ä¹ èµ„æ–™è·¯çº¿ç­‰\\ä¸­ç§‘é™¢è½¯ä»¶å®ä¹ é¡¹ç›®\\é¡¹ç›®å·¥ç¨‹æ–‡ä»¶æµ‹è¯•\\RussianVQA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import hashlib\n",
    "import argparse\n",
    "import requests\n",
    "import concurrent.futures as futures\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "from urllib.parse import urlparse\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === å…¨å±€è·¯å¾„é…ç½® ===\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "IMAGE_ROOT = os.path.join(DATA_DIR, \"images\", \"ru\")\n",
    "\n",
    "# è¾“å…¥æ–‡ä»¶ (è¯·ç¡®ä¿æ­¤æ–‡ä»¶å·²ä¸Šä¼ åˆ°å·¥ä½œç›®å½•)\n",
    "RAW_DATA_PATH = \"ru_image_caption.jsonl\"\n",
    "\n",
    "# ä¸­é—´äº§ç‰©\n",
    "CLEAN_JSON_PATH = os.path.join(DATA_DIR, \"ru_caption_clean.json\")\n",
    "SHAREGPT_PATH = os.path.join(DATA_DIR, \"ru_sharegpt.json\")\n",
    "\n",
    "# æœ€ç»ˆæ•°æ®é›†\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"ru_train.json\")\n",
    "EVAL_FILE = os.path.join(DATA_DIR, \"ru_eval.json\")\n",
    "\n",
    "# æ¨¡å‹ç›¸å…³\n",
    "MODEL_NAME = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "OUTPUT_DIR = \"saves/Qwen2-VL/lora/Qwen2-VL-sft-ru\"\n",
    "EXPORT_DIR = \"models/Qwen2-VL-sft-final\"\n",
    "\n",
    "# åˆ›å»ºå¿…è¦ç›®å½•\n",
    "os.makedirs(IMAGE_ROOT, exist_ok=True)\n",
    "print(f\"å·¥ä½œç›®å½•å·²å°±ç»ª: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æ•°æ®å¤„ç†ï¼šå›¾ç‰‡ä¸‹è½½\n",
    "\n",
    "è¯»å–åŸå§‹ JSONLï¼Œå¤šçº¿ç¨‹ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°ï¼Œè¿‡æ»¤æ‰ä¸å¯ä¸‹è½½çš„æ–‡ä»¶\n",
    "\n",
    "å¯é€‰æ‹©ä¸‹è½½çš„æ•°æ®é›†æ•°é‡ï¼Œæ›¿æ¢è·¯å¾„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹å¤„ç†å›¾ç‰‡ï¼Œæºæ–‡ä»¶: ru_image_caption.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [03:36<00:00,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä¸‹è½½å®Œæˆã€‚æˆåŠŸ: 1529/2000ã€‚ç»“æœå·²ä¿å­˜è‡³: e:\\Desktop\\aiç›¸å…³èµ„æ–™\\å­¦ä¹ èµ„æ–™è·¯çº¿ç­‰\\ä¸­ç§‘é™¢è½¯ä»¶å®ä¹ é¡¹ç›®\\é¡¹ç›®å·¥ç¨‹æ–‡ä»¶æµ‹è¯•\\RussianVQA\\data\\ru_caption_clean.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === é…ç½®ä¸‹è½½å‚æ•° ===\n",
    "MAX_DOWNLOAD_LINES = 2000  # é™åˆ¶å¤„ç†è¡Œæ•°ï¼Œ0ä¸ºå¤„ç†å…¨éƒ¨\n",
    "NUM_WORKERS = 32           # ä¸‹è½½å¹¶å‘æ•°\n",
    "\n",
    "# === æ ¸å¿ƒä¸‹è½½é€»è¾‘ ===\n",
    "FORMAT_EXT_MAP = {\n",
    "    \"JPEG\": \".jpg\", \"JPG\": \".jpg\", \"PNG\": \".png\",\n",
    "    \"WEBP\": \".webp\", \"BMP\": \".bmp\", \"GIF\": \".gif\",\n",
    "}\n",
    "\n",
    "def guess_ext(url: str, fmt: Optional[str]) -> str:\n",
    "    path = urlparse(url).path\n",
    "    suf = Path(path).suffix.lower()\n",
    "    if suf in {\".jpg\", \".jpeg\", \".png\", \".webp\", \".bmp\", \".gif\"}:\n",
    "        return \".jpg\" if suf == \".jpeg\" else suf\n",
    "    if fmt:\n",
    "        ext = FORMAT_EXT_MAP.get(fmt.upper())\n",
    "        if ext: return ext\n",
    "    return \".jpg\"\n",
    "\n",
    "def build_local_path(out_dir: Path, img_id: Optional[str], url: str, fmt: Optional[str]) -> Path:\n",
    "    ext = guess_ext(url, fmt)\n",
    "    if img_id and isinstance(img_id, str) and len(img_id) >= 2:\n",
    "        key = img_id\n",
    "    else:\n",
    "        key = hashlib.sha1(url.encode(\"utf-8\")).hexdigest()\n",
    "    subdir = key[:2]  # ä½¿ç”¨å‰ä¸¤ä½å“ˆå¸Œåˆ†æ¡¶\n",
    "    return out_dir / subdir / f\"{key}{ext}\"\n",
    "\n",
    "def make_session() -> requests.Session:\n",
    "    sess = requests.Session()\n",
    "    retries = Retry(total=3, backoff_factor=0.5, status_forcelist=[429, 500, 502, 503, 504])\n",
    "    adapter = HTTPAdapter(max_retries=retries, pool_connections=64, pool_maxsize=64)\n",
    "    sess.mount(\"http://\", adapter)\n",
    "    sess.mount(\"https://\", adapter)\n",
    "    return sess\n",
    "\n",
    "def process_line(line: str, out_dir: Path) -> Tuple[bool, Optional[str]]:\n",
    "    try:\n",
    "        rec = json.loads(line)\n",
    "    except: return False, None\n",
    "\n",
    "    image = rec.get(\"image\", {}) or {}\n",
    "    url = image.get(\"path\")\n",
    "    if not isinstance(url, str) or not url.startswith(\"http\"):\n",
    "        return False, None\n",
    "\n",
    "    local_path = build_local_path(out_dir, rec.get(\"img_id\"), url, image.get(\"format\"))\n",
    "    local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ä¸”éç©ºï¼Œè·³è¿‡ä¸‹è½½\n",
    "    if not (local_path.exists() and local_path.stat().st_size > 0):\n",
    "        try:\n",
    "            session = make_session()\n",
    "            with session.get(url, stream=True, timeout=5) as resp:\n",
    "                resp.raise_for_status()\n",
    "                with open(local_path, \"wb\") as f:\n",
    "                    for chunk in resp.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "        except Exception:\n",
    "            if local_path.exists(): local_path.unlink()\n",
    "            return False, None\n",
    "\n",
    "    image[\"path\"] = str(local_path.as_posix())\n",
    "    rec[\"image\"] = image\n",
    "    return True, json.dumps(rec, ensure_ascii=False)\n",
    "\n",
    "# === æ‰§è¡Œä¸‹è½½ä»»åŠ¡ ===\n",
    "print(f\"å¼€å§‹å¤„ç†å›¾ç‰‡ï¼Œæºæ–‡ä»¶: {RAW_DATA_PATH}\")\n",
    "if not os.path.exists(RAW_DATA_PATH):\n",
    "    print(\"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æºæ–‡ä»¶ï¼Œè¯·ä¸Šä¼  ru_image_caption.jsonl\")\n",
    "else:\n",
    "    lines = []\n",
    "    with open(RAW_DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        if MAX_DOWNLOAD_LINES > 0:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= MAX_DOWNLOAD_LINES: break\n",
    "                lines.append(line.strip())\n",
    "        else:\n",
    "            lines = [l.strip() for l in f]\n",
    "\n",
    "    success_cnt = 0\n",
    "    with open(CLEAN_JSON_PATH, \"w\", encoding=\"utf-8\") as fw:\n",
    "        with futures.ThreadPoolExecutor(max_workers=NUM_WORKERS) as ex:\n",
    "            tasks = [ex.submit(process_line, line, Path(IMAGE_ROOT)) for line in lines]\n",
    "            for fut in tqdm(futures.as_completed(tasks), total=len(tasks), desc=\"Downloading\"):\n",
    "                ok, res = fut.result()\n",
    "                if ok and res:\n",
    "                    fw.write(res + \"\\n\")\n",
    "                    success_cnt += 1\n",
    "    \n",
    "    print(f\"âœ… ä¸‹è½½å®Œæˆã€‚æˆåŠŸ: {success_cnt}/{len(lines)}ã€‚ç»“æœå·²ä¿å­˜è‡³: {CLEAN_JSON_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ•°æ®å¤„ç†ï¼šæ¸…æ´—ä¸æ ¼å¼è½¬æ¢\n",
    "\n",
    "æ¸…æ´—åå›¾å¹¶ä¸”å°†æ•°æ®è½¬æ¢ä¸ºshareGPTæ ¼å¼\n",
    "è¿™é‡Œå°† Prompt ç»Ÿä¸€è®¾ç½®ä¸ºä¿„è¯­é—®ç­”ï¼š**\"ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¾Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ ÑÑ‚Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ - Ñ€ÑƒÑÑĞºĞ¸.\"** (è¯·ç”¨ä¿„è¯­æè¿°è¿™å¼ å›¾ç‰‡)ã€‚\n",
    "\n",
    "shareGPTæ ·ä¾‹ï¼š  \n",
    "\n",
    "       {\n",
    "         \"messages\": [\n",
    "           {\"role\": \"user\", \"content\": \"<image>ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¾Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ ÑÑ‚Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ - Ñ€ÑƒÑÑĞºĞ¸.\"},\n",
    "           {\"role\": \"assistant\", \"content\": \"ĞĞ° ÑÑ‚Ğ¾Ğ¹ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½ ÑĞ¸Ğ¼Ğ¿Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ ĞºĞ¾Ñ‚ĞµĞ½Ğ¾Ğº, Ğ¸Ğ³Ñ€Ğ°ÑÑ‰Ğ¸Ğ¹ Ğ½Ğ° Ğ»ÑƒĞ¶Ğ°Ğ¹ĞºĞµ.\"},\n",
    "         ],\n",
    "         \"images\": [\"demo_data/1.jpg\"]\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹æ ¼å¼è½¬æ¢ä¸åå›¾æ¸…æ´—...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 1529it [00:25, 60.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è½¬æ¢å®Œæˆã€‚æœ‰æ•ˆæ•°æ®: 1529 æ¡ã€‚ä¿å­˜è‡³: e:\\Desktop\\aiç›¸å…³èµ„æ–™\\å­¦ä¹ èµ„æ–™è·¯çº¿ç­‰\\ä¸­ç§‘é™¢è½¯ä»¶å®ä¹ é¡¹ç›®\\é¡¹ç›®å·¥ç¨‹æ–‡ä»¶æµ‹è¯•\\RussianVQA\\data\\ru_sharegpt.json\n"
     ]
    }
   ],
   "source": [
    "def verify_image(path):\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            img.verify()\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "print(\"å¼€å§‹æ ¼å¼è½¬æ¢ä¸åå›¾æ¸…æ´—...\")\n",
    "sharegpt_data = []\n",
    "valid_count = 0\n",
    "\n",
    "if os.path.exists(CLEAN_JSON_PATH):\n",
    "    with open(CLEAN_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in tqdm(f, desc=\"Processing\"):\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                img_path = data.get(\"image\", {}).get(\"path\")\n",
    "                caption = data.get(\"captions\", {}).get(\"content\")\n",
    "                \n",
    "                # æ ¡éªŒå›¾ç‰‡\n",
    "                if not img_path or not os.path.exists(img_path) or not verify_image(img_path):\n",
    "                    continue\n",
    "                \n",
    "                # æ„å»º ShareGPT æ ¼å¼ (éŸ©è¯­ Prompt)\n",
    "                entry = {\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"user\", \"content\": \"<image>ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¾Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ ÑÑ‚Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ - Ñ€ÑƒÑÑĞºĞ¸.\"}, \n",
    "                        {\"role\": \"assistant\", \"content\": caption}\n",
    "                    ],\n",
    "                    \"images\": [img_path]\n",
    "                }\n",
    "                sharegpt_data.append(entry)\n",
    "                valid_count += 1\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    # ä¿å­˜ç»“æœ\n",
    "    with open(SHAREGPT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(sharegpt_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"âœ… è½¬æ¢å®Œæˆã€‚æœ‰æ•ˆæ•°æ®: {valid_count} æ¡ã€‚ä¿å­˜è‡³: {SHAREGPT_PATH}\")\n",
    "else:\n",
    "    print(\"âŒ æœªæ‰¾åˆ°ä¸‹è½½åçš„æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œæ­¥éª¤ 2ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ•°æ®å¤„ç†ï¼šæ•°æ®é›†åˆ†å‰²\n",
    "\n",
    "å°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†ä¸éªŒè¯é›†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åˆ†å‰²å®Œæˆã€‚\n",
      "   è®­ç»ƒé›†: 1459 -> e:\\Desktop\\aiç›¸å…³èµ„æ–™\\å­¦ä¹ èµ„æ–™è·¯çº¿ç­‰\\ä¸­ç§‘é™¢è½¯ä»¶å®ä¹ é¡¹ç›®\\é¡¹ç›®å·¥ç¨‹æ–‡ä»¶æµ‹è¯•\\RussianVQA\\data\\ru_train.json\n",
      "   éªŒè¯é›†: 70 -> e:\\Desktop\\aiç›¸å…³èµ„æ–™\\å­¦ä¹ èµ„æ–™è·¯çº¿ç­‰\\ä¸­ç§‘é™¢è½¯ä»¶å®ä¹ é¡¹ç›®\\é¡¹ç›®å·¥ç¨‹æ–‡ä»¶æµ‹è¯•\\RussianVQA\\data\\ru_eval.json\n"
     ]
    }
   ],
   "source": [
    "N_EVAL = 70  # éªŒè¯é›†æ•°é‡\n",
    "SEED = 42\n",
    "\n",
    "if os.path.exists(SHAREGPT_PATH):\n",
    "    with open(SHAREGPT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        all_data = json.load(f)\n",
    "    \n",
    "    total = len(all_data)\n",
    "    random.seed(SEED)\n",
    "    random.shuffle(all_data)\n",
    "    \n",
    "    # ç¡®ä¿æ•°æ®é‡è¶³å¤Ÿ\n",
    "    if total <= N_EVAL:\n",
    "        n_eval = int(total * 0.1)\n",
    "    else:\n",
    "        n_eval = N_EVAL\n",
    "        \n",
    "    n_train = total - n_eval\n",
    "    train_data = all_data[:n_train]\n",
    "    eval_data = all_data[n_train:]\n",
    "    \n",
    "    with open(TRAIN_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(train_data, f, ensure_ascii=False, indent=2)\n",
    "    with open(EVAL_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(eval_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "    print(f\"âœ… åˆ†å‰²å®Œæˆã€‚\\n   è®­ç»ƒé›†: {len(train_data)} -> {TRAIN_FILE}\\n   éªŒè¯é›†: {len(eval_data)} -> {EVAL_FILE}\")\n",
    "else:\n",
    "    print(\"âŒ æ‰¾ä¸åˆ° ShareGPT æ•°æ®æ–‡ä»¶ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ä¸‹è½½åº•åº§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c82c8b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Git hooks.\n",
      "Git LFS initialized.\n",
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'models/Qwen2-VL-2B-Instruct'...\n",
      "Updating files:  66% (10/15)\n",
      "Updating files:  73% (11/15)\n",
      "Updating files:  80% (12/15)\n",
      "Updating files:  86% (13/15)\n",
      "Updating files:  93% (14/15)\n",
      "Updating files: 100% (15/15)\n",
      "Updating files: 100% (15/15), done.\n",
      "Filtering content: 100% (2/2)\n",
      "Filtering content: 100% (2/2), 4.11 GiB | 10.57 MiB/s\n",
      "Filtering content: 100% (2/2), 4.11 GiB | 9.22 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git lfs install\n",
    "!git clone https://www.modelscope.cn/Qwen/Qwen2-VL-2B-Instruct.git models/Qwen2-VL-2B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf9c8ce",
   "metadata": {},
   "source": [
    "## 5. æ³¨å†Œæ•°æ®é›†\n",
    "\n",
    "å°†ç”Ÿæˆçš„ json æ–‡ä»¶è·¯å¾„å†™å…¥ LLaMA-Factory çš„ `dataset_info.json` ä¸­ï¼Œä»¥ä¾¿æ¡†æ¶è¯†åˆ«ã€‚**\n",
    "\n",
    "       \"ru_train\": {\n",
    "         \"path\": \"data/ru_train.json\",\n",
    "         \"type\": \"sharegpt_multi_modal\"\n",
    "       },\n",
    "       \"ru_val\": {\n",
    "         \"path\": \"data/ru_val.json\",\n",
    "         \"type\": \"sharegpt_multi_modal\"\n",
    "       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æ¨¡å‹å¾®è°ƒ (LoRA)\n",
    "\n",
    "ä½¿ç”¨ LLaMA-Factory CLI å¯åŠ¨è®­ç»ƒã€‚\n",
    "\n",
    "### å…³é”®å‚æ•°ç¤ºä¾‹ï¼š\n",
    "\n",
    "   | é€‰é¡¹ | å€¼ |\n",
    "   | ---- | -- |\n",
    "   | Model name  | Qwen2-VL-2B-Instruct |\n",
    "   | Model path  | models/Qwen2-VL-2B-Instruct |\n",
    "   | Finetune    | LoRA |\n",
    "   | Stage       | Supervised Fine-Tuning |\n",
    "   | Dataset     | ru_train |\n",
    "   | Max epochs  | 3 |\n",
    "   | Batch size  | 16 |\n",
    "   | Save steps  | 200 |\n",
    "   | lora_rank   | 64 |\n",
    "   | lora_alpha  | 128ï¼ˆä¸€èˆ¬æ˜¯rankçš„ä¸¤å€ï¼‰ |\n",
    "   | lora_dropout | 0.05ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰ |\n",
    "   | Output dir  | saves/Qwen2-VL/lora/Qwen2-VL-sft-ru |\n",
    "\n",
    "### ç›‘æ§æ˜¾å­˜  \n",
    "      watch -n 1 nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ¨¡å‹å¯¼å‡º\n",
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œå°† LoRA æƒé‡åˆå¹¶åˆ°åº•åº§æ¨¡å‹ä¸­ï¼Œä»¥ä¾¿åœ¨ OrangePi ä¸Šéƒ¨ç½²ã€‚\n",
    "\n",
    "åœ¨ WebUI **Expert** æ ‡ç­¾æ‰§è¡Œ  \n",
    "\n",
    "    Model path      = models/Qwen2-VL-2B-Instruct\n",
    "    Checkpoint path = saves/Qwen2-VL/lora/Qwen2-VL-sft-ru\n",
    "    Export path     = models/qwen2ru_final\n",
    "\n",
    "ç‚¹å‡»â€œå¼€å§‹å¯¼å‡ºâ€ï¼Œå¾—åˆ°åˆå¹¶æƒé‡ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
